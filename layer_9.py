# -*- coding: utf-8 -*-
"""Layer 9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pd5lIIT0JmiKKOnHfqjKemJEZ-mNOXyt
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, chi2
from sklearn.model_selection import RandomizedSearchCV

def predictAndGetAccuracyScore(model, x_valid, y_valid):
    y_pred = model.predict(x_valid)
    accuracy =  accuracy_score(y_valid, y_pred)
    print("Accuracy: %.2f%%" % (accuracy * 100.0))
    return accuracy

# file paths for the datasets
train_path = '/content/drive/MyDrive/Colab Notebooks/ML-labs/Kaggle Comp/data/train.csv'
valid_path = '/content/drive/MyDrive/Colab Notebooks/ML-labs/Kaggle Comp/data/valid.csv'
test_path = '/content/drive/MyDrive/Colab Notebooks/ML-labs/Kaggle Comp/data/test.csv'

train_data = pd.read_csv(train_path)
valid_data = pd.read_csv(valid_path)
test_data = pd.read_csv(test_path)

X_train = train_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
y_test_train = train_data["label_1"]

X_valid = valid_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
Y_valid = valid_data["label_1"]

X_test = valid_data.drop(columns=["label_1", "label_2", "label_3", "label_4"])
Y_test = valid_data["label_1"]

x_train = {}
x_valid = {}
y_train = {}
y_valid = {}
x_test = {}
y_test = {}
Labels = ["label_1", "label_2", "label_3", "label_4"]
Features = np.array(train_data.drop(columns=["label_1", "label_2", "label_3", "label_4"]).columns)

for label in Labels:
  tr_data = train_data[train_data["label_2"].notna()] if label == "label_2" else train_data
  vl_data = valid_data[valid_data["label_2"].notna()] if label == "label_2" else valid_data

  scaler = StandardScaler()

  x_train[label] = pd.DataFrame(scaler.fit_transform(tr_data.drop(Labels, axis=1)), columns=Features)
  y_train[label] = tr_data[label]
  x_valid[label] = pd.DataFrame(scaler.transform(vl_data.drop(Labels, axis=1)), columns=Features)
  y_valid[label] = vl_data[label]
  x_test[label] = pd.DataFrame(scaler.transform(test_data.drop(["ID"], axis=1)), columns=Features)

"""#Label 1 - Speaker"""

###### Initial accuracy with svm_model
svm_model_1 = SVC(kernel="linear")
svm_model_1.fit(x_train["label_1"], y_train["label_1"])
accuracy_label_1 = predictAndGetAccuracyScore(svm_model_1, x_valid["label_1"], y_valid["label_1"])

#Apply PCA -Feature Extraction
pca_label_1 = PCA(n_components=0.99, svd_solver="full")
pca_label_1.fit(x_train["label_1"])
x_train_label_1_PCA = pd.DataFrame(pca_label_1.transform(x_train["label_1"]))
print(x_train_label_1_PCA.shape)
x_valid_label_1_PCA = pd.DataFrame(pca_label_1.transform(x_valid["label_1"]))

#Hyper parameter tuning
param_dist = {
    'C': [100, 10, 1],
    'kernel': ['rbf'],
    'gamma': [0.001,0.01, 0.1],
}

# Create a RandomizedSearchCV object
random_search_label_1 = RandomizedSearchCV(
    SVC(),
    param_distributions=param_dist,
    n_iter=2,       # Number of parameter settings sampled
    cv=5,             # Number of cross-validation folds
    verbose=1,
    n_jobs=-1         # Use all CPU cores
)

random_search_label_1.fit(x_train_label_1_PCA, y_train["label_1"])

# Get the best hyperparameters and the corresponding model
best_model_label_1 = random_search_label_1.best_estimator_

print(f"Best parameter : {random_search_label_1.best_params_}")
print(f"Best Score : {random_search_label_1.best_score_}")

# Evaluate the best model on your validation set
acc_best_model_label_1 = best_model_label_1.score(
    x_valid_label_1_PCA, y_valid["label_1"])

print("Validation Accuracy with Best Model:", acc_best_model_label_1)

y_pred_label_1 = best_model_label_1.predict(pca_label_1.transform(x_test["label_1"]))

result_df = pd.DataFrame({'ID': test_data['ID'], 'label_1': y_pred_label_1})

"""#Label 2 - Age"""

###### Initial accuracy with svm_model

svm_model_2 = SVC()
svm_model_2.fit(x_train["label_2"], y_train["label_2"])
acc = predictAndGetAccuracyScore(svm_model_2, x_valid["label_2"], y_valid["label_2"])

#Apply PCA - Feature Extraction
pca_label_2 = PCA(n_components=0.96, svd_solver="full")
pca_label_2.fit(x_train["label_2"])
x_train_label_2_PCA = pd.DataFrame(pca_label_2.transform(x_train["label_2"]))
print(x_train_label_2_PCA.shape)
x_valid_label_2_PCA = pd.DataFrame(pca_label_2.transform(x_valid["label_2"]))

svm_model_2.fit(x_train_label_2_PCA, y_train["label_2"])
acc = predictAndGetAccuracyScore(svm_model_2, x_valid_label_2_PCA, y_valid["label_2"])

#Hyper parameter tuning
param_dist = {
    'C': [0.1, 1, 10],
    'kernel': ['rbf','linear'],
    'gamma': [0.001, 0.1, 1],
    'degree': [1, 2]
}

# Create a RandomizedSearchCV object
random_search_label_2 = RandomizedSearchCV(
    SVC(),
    param_distributions=param_dist,
    n_iter=2,       # Number of parameter settings sampled
    cv=5,             # Number of cross-validation folds
    verbose=1,
    n_jobs=-1         # Use all CPU cores
)

random_search_label_2.fit(x_train_label_2_PCA, y_train["label_2"])

# Get the best hyperparameters and the corresponding model
best_model_label_2 = random_search_label_2.best_estimator_

acc_best_model_label_2 = predictAndGetAccuracyScore(best_model_label_2, x_valid_label_2_PCA, y_valid["label_2"])

y_pred_label_2 = best_model_label_2.predict(pca_label_2.transform(x_test["label_2"]))

result_df['label_2'] = y_pred_label_2

"""#Label 3 - Gender"""

###### Initial accuracy with svm_model
svm_model_3 = SVC(kernel="linear")
svm_model_3.fit(x_train["label_3"], y_train["label_3"])
acc = predictAndGetAccuracyScore(svm_model_3, x_valid["label_3"], y_valid["label_3"])

#Apply PCA - Feature Extraction
pca_label_3 = PCA(n_components=0.85, svd_solver="full")
pca_label_3.fit(x_train["label_3"])
x_train_label_3_PCA = pd.DataFrame(pca_label_3.transform(x_train["label_3"]))
print(x_train_label_3_PCA.shape)
x_valid_label_3_PCA = pd.DataFrame(pca_label_3.transform(x_valid["label_3"]))

svm_model_3.fit(x_train_label_3_PCA, y_train["label_3"])
acc = predictAndGetAccuracyScore(svm_model_3, x_valid_label_3_PCA, y_valid["label_3"])

from scipy.stats import reciprocal, uniform

#Hyper parameter tuning
param_dist = {
    'C': uniform(loc=0, scale=10),
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],
    'gamma': reciprocal(0.001, 1),
    'degree': [2, 3, 4, 5, 6]
}

# Create a RandomizedSearchCV object
random_search_label_3 = RandomizedSearchCV(
    SVC(),
    param_distributions=param_dist,
    n_iter=10,       # Number of parameter settings sampled
    cv=5,             # Number of cross-validation folds
    verbose=1,
    n_jobs=-1         # Use all CPU cores
)

random_search_label_3.fit(x_train_label_3_PCA, y_train["label_3"])

# Get the best hyperparameters and the corresponding model
best_model_label_3 = random_search_label_3.best_estimator_

acc_best_model_label_3 = predictAndGetAccuracyScore(best_model_label_3, x_valid_label_3_PCA, y_valid["label_3"])

y_pred_label_3 = best_model_label_3.predict(pca_label_3.transform(x_test["label_3"]))

result_df['label_3'] = y_pred_label_3

"""#Label 4 - Accent"""

###### Initial accuracy with svm_model
svm_model_4 = SVC()
svm_model_4.fit(x_train["label_4"], y_train["label_4"])
acc = predictAndGetAccuracyScore(
    svm_model_4, x_valid["label_4"], y_valid["label_4"])

pca_label_4 = PCA(n_components=0.91, svd_solver="full")
pca_label_4.fit(x_train["label_4"])
x_train_label_4_PCA = pd.DataFrame(pca_label_4.transform(x_train["label_4"]))
print(x_train_label_4_PCA.shape)
x_valid_label_4_PCA = pd.DataFrame(pca_label_4.transform(x_valid["label_4"]))

svm_model_4.fit(x_train_label_4_PCA, y_train["label_4"])
acc = predictAndGetAccuracyScore(svm_model_4, x_valid_label_4_PCA, y_valid["label_4"])

label_4_param_dist = {
    # Continuous uniform distribution for 'C'
    'C': [100, 10, 1, 0.1],
    'kernel': ['rbf'],  # Categorical distribution for 'kernel'
    'gamma': [0.001, 0.01, 0.1, 1],
    # Add more hyperparameters and their distributions as needed
}

# Create a RandomizedSearchCV object
random_search_label_4 = RandomizedSearchCV(
    SVC(),
    param_distributions=param_dist,
    n_iter=3,       # Number of parameter settings sampled
    cv=5,             # Number of cross-validation folds
    verbose=1,
    n_jobs=-1         # Use all CPU cores
)

random_search_label_4.fit(x_train_label_4_PCA, y_train["label_4"])

# Get the best hyperparameters and the corresponding model
best_model_label_4 = random_search_label_4.best_estimator_

acc_best_model_label_4 = predictAndGetAccuracyScore(best_model_label_4, x_valid_label_4_PCA, y_valid["label_4"])

y_pred_label_4 = best_model_label_4.predict(pca_label_4.transform(x_test["label_4"]))

result_df['label_4'] = y_pred_label_4

"""#Writing the final CSV"""

result_df.to_csv("solutions9.csv", index=False)

destination = '/content/drive/MyDrive/Colab Notebooks/ML-labs/Kaggle Comp/data/190375K_Layer9.csv'

result_df.to_csv(destination, index=False)

